\documentclass{article}
\usepackage[a4paper, margin=2.5cm]{geometry}
\begin{document}
\title{Task 5: Jarnik-Prim on Sample-MST with Filter}
\author{Lucas Alber (***REMOVED***), Noah Wahl (***REMOVED***)}
\maketitle

\section{Implementation}

Every step of our implementation was carefully evaluated using micro benchmarks. The following subsections present our findings.

\subsection{Sampling}
\textbf{Problem:} We receive undirected edges as directed edges in both directions from the graph generator.
However, the sampling would be far easier if these edges were only present in one direction, to prevent accidentally sampling duplicates.

\noindent \\
\textbf{Solution:} We went through multiple sampling strategies:

\begin{enumerate}
\item \texttt{std::mt19937}: Select an edge \texttt{e if e.tail < e.head} with probability $p = n / \sqrt{n \times m} = \sqrt{n / m}$.
This turned out to be very slow because branch miss-predictions on these conditions are very common and we have to iterate over the whole edge list.

\item \texttt{std::mt19937}: Select $\sqrt{n \times m}$ edges \texttt{edge\_list[x\_i]} where \texttt{x\_i} is sampled uniformly from \texttt{[0, edge\_list.size() - 1]}.
This way we may sample edges twice, but we found this to not diminish the quality of the sample.

\item \texttt{XORShift128}: Same as 2. but with a faster random number generator.
We could not detect any compromise in quality.

\item Deterministic Sampling: Select every \texttt{edge\_list.size() / $\sqrt{n \times m}$}-th edge from the edge list.
This was more than an order of magnitude faster than relying on random number generators at no disadvantage to the quality of the sample.
So we settled for this strategy in our final implementation.
\end{enumerate}

\subsection{Graph Representation}
We use single undirected edges where possible and only add reverse edges during the adjacency array buildup for the Jarnik-Prim subroutine.
The edges in the adjacency array are reduced to weight-head pairs instead of carrying the tail as well.

\subsection{Range Maximum Queries (RMQ)}
We expand the levels to the next power of two allowing for efficient shift operations instead of multiplications.
This also eliminates special cases in the buildup. We also flattened the levels into one single array.

To speed up the filter loop condition for including edges between components, we set the weight of the root node in each component to $\inf$.
In this regard we deviate from the paper where the weight of the root node is set to zero.
This way, queries across boundaries return $\inf$ and the condition \texttt{e.weight < query(e)} evaluates to true.

\subsection{Jarnik-Prim}
Our Jarnik-Prim implementation is very straight forward. We use a specialized version for computing the minimum spanning forest for our sampled edges and combine data that is accessed together to minimize cache misses. For edge priorities we use an indexed priority queue implementation which turned out to be faster than \texttt{std::priority\_queue}, especially for dense graphs.

\subsection{Filter Loop}
The filter loop turned out to be the main bottleneck because we need to check the filter condition for each edge. However, through the aforementioned techniques we reduced the number of computations to a minimum. Additionally, we split the query on the range maximum query data structure to allow for short-circuit evaluation because in this case cache misses (on the RMQ data structure) were more expensive than branch miss-predictions.

\subsection{Exploit Simple Instances}
Finally, our algorithm decides based on the expected runtime of Jarnik-Prim and IMaxFilter whether to run only a single Jarnik-Prim iteration or run the full IMaxFilter algorithm which can provide a speedup of two for small instances.

\subsection{Parallel IMaxFilter}
We added a simple parallel implementation of our IMaxFilter that uses OpenMP to speed up the filter loop.

\section{Experiments}
Our implementation was evaluated on a machine running Arch GNU/Linux 64bit on Linux 5.18.14 with an AMD Ryzen 5800X, 8 Cores (16 Threads) @ 3800 MHz and 4 $\times$ 8 GB DDR4 RAM @ 3400 MT/s.
We used GCC 12.1.0 to compile the code and did not change any flags.

\end{document}
