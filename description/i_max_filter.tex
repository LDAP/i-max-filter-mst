\documentclass{article}
\usepackage[a4paper, margin=1.5in]{geometry}
\begin{document}
\title{Task 5: Jarnik-Pim on Sample-MST with Filter}
\author{Lucas Alber, Noah Wahl}
\maketitle

\section{Sampling}
\textbf{Problem:} We receive undirected edges as directed edges in both directions from the graph generator.
However, the sampling would be far easier if these edges were only present in one direction, to prevent accidentally sampling duplicates.

\noindent \\
\textbf{Solution:} We went through multiple sampling strategies:

\begin{enumerate}
  \item \texttt{std::mt19937}: Select an edge \texttt{e if e.tail < e.head} with probability $p = n / \sqrt{n\*m} = \sqrt{n/m}$.
This turned out to be very slow because branch miss-predictions on these conditions are very common and we have to iterate over the whole edge list.

\item \textit{std::mt19937}: Select $\sqrt{n\*m}$ edges \texttt{edge\_list[x\_i]} where \texttt{x\_i} is sampled uniformly from \texttt{[0, edge\_list.size() - 1]}.
This way we may sample edges twice, but we found this to not diminish the quality of the sample.

\item. \texttt{XORShift128}: Same as 2. but with a faster random number generator.
We could not detect any compromise in quality.

\item Deterministic Sampling: Select every \texttt{edge\_list.size() / $\sqrt{n*m}$}-th edge from the edge list.
This was more than an order of magnitude faster than relying on random number generators at no disadvantage to the quality of the sample.
So we settled for this strategy in our final implementation.
\end{enumerate}

\section{Graph Representation}
We use single undirected edges where possible and only add reverse edges during the adjacency array buildup for the Jarnik-Prim subroutine.
The edges in the adjacency array are reduced to weight-head pairs instead of carrying the tail as well.

\section{Range Maximum Queries}
We expand the levels to the next power of two allow for efficient shift operations instead of multiplications.
This allows us to simplify the buildup. We also flattened the levels into one single array.

To speedup the filter loop condition for including edges between components, we set the weight of the root node in each component to $\inf$.
This way, queries across boundaries return $\inf$ and the condition \texttt{e.weight < query(e)} evaluates to true.

\section{Jarnik-Prim}
Our Jarnik-Prim implementation is very straight forward. We use a specialized version for computing the minimum spanning forest for our sampled edges and combine data that is accessed together to minimize cache misses. For edge priorities we use an indexed priority queue implementation which turned out to be faster than \texttt{std::priority\_queue}, especially for dense graphs.

\section{Filter Loop}
The filter loop turned out to be the main bottleneck because we need to check the filter condition for each edge. However, through the aforementioned techniques we reduced the computations as best as possible. Additionally, we split the split the query on the range maximum query data structure to allow for short-circuit evaluation because in this case cache misses are more expensive than branch miss-predictions.

\section{Exploit Simple Instances}
Finally, our algorithm decides based on the expected runtime of Jarnik-Prim and IMaxFilter whether to run only a single Jarnik-Prim iteration or run the full IMaxFilter algorithm.

\section{Parallel IMaxFilter}
We added a simple parallel implementation of our IMaxFilter that uses OpenMP to speed up the filter loop.
\end{document}
